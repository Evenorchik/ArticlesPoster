# migrate_sqlite_to_postgres.py
import os
import sqlite3
import logging
from contextlib import closing
from typing import List, Tuple, Dict

# psycopg v3
import psycopg
from psycopg import sql
from psycopg.rows import dict_row

# ---- config ----
# Берём твои настройки из config.py:
# SQLITE_DB_FILENAME = "articles.db"     # рядом со скриптом
# POSTGRES_DSN = "postgresql://fraxi:Art1clesss@194.163.130.97:5432/articles"
try:
    from config import SQLITE_DB_FILENAME, POSTGRES_DSN
except Exception:
    # Фолбэк — но лучше положить значения в config.py
    SQLITE_DB_FILENAME = "articles.db"
    POSTGRES_DSN = "postgresql://fraxi:Art1clesss@194.163.130.97:5432/articles?connect_timeout=10"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# --------- helpers ---------
def sqlite_path() -> str:
    base_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(base_dir, SQLITE_DB_FILENAME)

def pg_quote_ident(name: str) -> sql.Identifier:
    """
    Возвращаем psycopg.sql.Identifier для безопасной вставки имени таблицы/колонки.
    Это автоматически поставит двойные кавычки и экранирует.
    """
    return sql.Identifier(name)

def fetch_sqlite_tables(conn: sqlite3.Connection) -> List[str]:
    """
    Находим таблицы:
    - raw_articles
    - все Refined_articles-*
    - а также совместимость: refinedarticle (старое имя)
    """
    with closing(conn.cursor()) as cur:
        cur.execute("""
            SELECT name FROM sqlite_master
            WHERE type='table' AND name NOT LIKE 'sqlite_%'
        """)
        names = [r[0] for r in cur.fetchall()]

    wanted = []
    for n in names:
        if n == "raw_articles":
            wanted.append(n)
        elif n == "refinedarticle":
            wanted.append(n)
        elif n.startswith("Refined_articles-"):
            wanted.append(n)
    return wanted

def sqlite_table_columns(conn: sqlite3.Connection, table: str) -> List[Tuple[int, str, str, int, str, int]]:
    """
    PRAGMA table_info(table) -> список колонок:
    (cid, name, type, notnull, dflt_value, pk)
    """
    with closing(conn.cursor()) as cur:
        cur.execute(f'PRAGMA table_info("{table}")')
        return cur.fetchall()

def ensure_pg_table_raw(pg_conn: psycopg.Connection) -> None:
    """
    Создать raw_articles в Postgres, если нет.
    id делаем GENERATED BY DEFAULT AS IDENTITY, чтобы можно было вставлять свои id.
    """
    q = """
    CREATE TABLE IF NOT EXISTS raw_articles (
        id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        topic TEXT,
        title TEXT,
        body TEXT
    )
    """
    with pg_conn.cursor() as cur:
        cur.execute(q)
    pg_conn.commit()

def ensure_pg_table_refined(pg_conn: psycopg.Connection, table_name: str) -> None:
    """
    Создать табличку refined в Postgres, с именем как в SQLite (в кавычках).
    """
    # точная структура под наши текущие скрипты
    q = sql.SQL("""
        CREATE TABLE IF NOT EXISTS {tname} (
            id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            topic TEXT,
            title TEXT,
            body TEXT,
            links TEXT,
            keywords TEXT,
            hashtag1 TEXT,
            hashtag2 TEXT,
            hashtag3 TEXT,
            hashtag4 TEXT,
            url TEXT,
            approval TEXT,
            created_at TEXT
        )
    """).format(tname=pg_quote_ident(table_name))
    with pg_conn.cursor() as cur:
        cur.execute(q)
    pg_conn.commit()

def batched(iterable, n: int):
    buf = []
    for item in iterable:
        buf.append(item)
        if len(buf) >= n:
            yield buf
            buf = []
    if buf:
        yield buf

# --------- migrations ---------
def migrate_raw_articles(sqlite_conn: sqlite3.Connection, pg_conn: psycopg.Connection) -> None:
    logging.info("Migrating table: raw_articles")
    ensure_pg_table_raw(pg_conn)

    with closing(sqlite_conn.cursor()) as cur:
        cur.execute("SELECT id, topic, title, body FROM raw_articles ORDER BY id")
        rows = cur.fetchall()

    if not rows:
        logging.info("No rows in raw_articles")
        return

    insert_q = """
        INSERT INTO raw_articles (id, topic, title, body)
        VALUES (%s, %s, %s, %s)
        ON CONFLICT (id) DO NOTHING
    """
    total = 0
    with pg_conn.cursor() as cur:
        for chunk in batched(rows, 1000):
            cur.executemany(insert_q, chunk)
            total += len(chunk)
        pg_conn.commit()
    logging.info("raw_articles migrated: %d row(s)", total)

def migrate_refined_table(sqlite_conn: sqlite3.Connection, pg_conn: psycopg.Connection, table_name: str) -> None:
    logging.info("Migrating table: %s", table_name)
    ensure_pg_table_refined(pg_conn, table_name)

    with closing(sqlite_conn.cursor()) as cur:
        cur.execute(f"""
            SELECT
                id, topic, title, body, links, keywords,
                hashtag1, hashtag2, hashtag3, hashtag4,
                url, approval, created_at
            FROM "{table_name}"
            ORDER BY id
        """)
        rows = cur.fetchall()

    if not rows:
        logging.info("%s: no rows", table_name)
        return

    insert_q = sql.SQL("""
        INSERT INTO {tname}
            (id, topic, title, body, links, keywords,
             hashtag1, hashtag2, hashtag3, hashtag4,
             url, approval, created_at)
        VALUES
            (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
        ON CONFLICT (id) DO NOTHING
    """).format(tname=pg_quote_ident(table_name))

    total = 0
    with pg_conn.cursor() as cur:
        for chunk in batched(rows, 500):
            cur.executemany(insert_q.as_string(pg_conn), chunk)
            total += len(chunk)
        pg_conn.commit()
    logging.info("%s migrated: %d row(s)", table_name, total)

def main():
    # 1) SQLite connect
    s_path = sqlite_path()
    if not os.path.exists(s_path):
        logging.error("SQLite file not found: %s", s_path)
        return

    sqlite_conn = sqlite3.connect(s_path)
    try:
        # 2) PG connect (pool не обязателен, но можно)
        with psycopg.connect(POSTGRES_DSN, row_factory=dict_row) as pg_conn:
            # 3) список таблиц для миграции
            tables = fetch_sqlite_tables(sqlite_conn)
            if not tables:
                logging.warning("No relevant tables found in SQLite")
                return

            # 4) прогоняем
            if "raw_articles" in tables:
                migrate_raw_articles(sqlite_conn, pg_conn)

            for t in tables:
                if t == "raw_articles":
                    continue
                migrate_refined_table(sqlite_conn, pg_conn, t)

            logging.info("Migration complete.")
    finally:
        sqlite_conn.close()

if __name__ == "__main__":
    main()
